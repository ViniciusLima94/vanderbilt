


import sys

sys.path.insert(1, "/home/vinicius/storage1/projects/vanderbilt")


import os

import h5py
import matplotlib.pyplot as plt
import numpy as np
from tqdm import tqdm


from VUDA.io.loadbinary import LoadBinary


ROOT = os.path.expanduser("~/funcog/Neural Data/FN - LaDy/10-15-2022")


filepath = os.path.join(ROOT, "aHPC_B_cnct.dat")
tspath = os.path.join(ROOT, "timestamps.mat")


# aHPC_B_cnct.dat - includes CA1
# pHPC - posterior HIPPOCMAPUS





perpl_LoadBinary?





data = LoadBinary(
    filepath,
    frequency=30000,
    nSamplesPerChannel=3000,
    channels=None,
    downsample=1,
    bitVolts=0.195,
    nChannels=64,
    precision=np.int16,
    verbose=False,
)


print(data)
print(data.shape)


plt.figure(figsize=(20, 20))
for i in range(data.shape[1]):
    plt.subplot(11, 6, i + 1)
    plt.plot(data[:, i])
    plt.title(f"Channel {i + 1}")
    plt.axis("off")
plt.tight_layout()





downsample = [1, 10, 20]
channels = [1, 5, 10, 23, 55]

















from VUDA.io.dataloader import DataLoader


DataLoader?


rec_info = os.path.expanduser(
    "/home/vinicius/storage1/projects/vanderbilt/recording_params.json"
)


loader = DataLoader(filepath, rec_info)


loader.loadbinary(nSamplesPerChannel=100000, downsample=30, verbose=True)


loader.data.plot(hue="channels", color="b", lw=0.1)
plt.legend([], frameon=False)


loader.filter(0, 120, {})


loader.data.plot(hue="channels", color="b", lw=0.1)
plt.legend([], frameon=False)





import pandas as pd

from config import metadata


date = "10-20-2022"
monkey = "FN"


ROOT = os.path.expanduser(f"~/funcog/Neural Data/{monkey} - LaDy/{date}")
filepath = os.path.join(ROOT, "aHPC_B_cnct.dat")
tspath = os.path.join(ROOT, "timestamps.mat")


info = pd.read_excel(metadata["rec_info"])


info.columns


attrs =  info.loc[np.logical_and(info.Date == date, info.Animal_ID == "FN")]


attrs.to_dict()


n_channels = attrs["Num_chan"].values[0]


timestamps = np.asarray(h5py.File(tspath).get("timestamps")).squeeze()


data = LoadBinary(
    filepath,
    frequency=30000,
    nSamplesPerChannel=np.inf,
    channels=[0],
    downsample=30,
    bitVolts=0.195,
    nChannels=n_channels,
    precision=np.int16,
    timestamps=timestamps,
    attrs=attrs.to_dict(),
    verbose=False,
)


plt.figure(figsize=(15, 4))
plt.plot(data.squeeze())


data


data.shape


timestamps[::30].shape


metadata = {}
metadata["rec_info"] = r"/home/vinicius/funcog/Neural\ Data/Data_Processed.xlsx"
metadata["monkey"] = ["FN - LaDy" :  {}, "WI - LaDy" :  {}]
metadata["monkey"] = {"FN - LaDy": {}, "WI - LaDy": {}}


import jax
import jax.numpy as jnp
from jax import lax


def set_values_scan(carry, element):
    # `carry` represents the state of the computation, and `element` is the current array element.
    array, value_to_set = carry

    # Update the array by setting its values.
    updated_array = lax.dynamic_update_slice(array, value_to_set, [element])

    # Update the state for the next iteration.
    new_carry = (updated_array, value_to_set)

    return new_carry, None


def set_values_loop(array, values_to_set):
    # Initialize the state for the scan operation.
    initial_carry = (array, values_to_set)

    # Perform the scan operation using jax.lax.scan.
    final_carry, _ = lax.scan(set_values_scan, initial_carry, jnp.arange(array.size))

    # The updated array is the final state of the computation.
    updated_array, _ = final_carry

    return updated_array


# Example usage:
array_size = 5
initial_array = jnp.zeros(array_size)
values_to_set = jnp.array([1.0, 2.0, 3.0, 4.0, 5.0])

result = set_values_loop(initial_array, values_to_set)
print(result)


import jax
import jax.numpy as jnp
from jax import lax


def update_matrix_slices(matrix, values, row_indices, col_indices):
    # Update the matrix by setting the specified slices to the given values.
    updated_matrix = lax.dynamic_update_slice(
        matrix, values, [row_indices, col_indices]
    )
    return updated_matrix


# Example usage:
n = 5
matrix = jnp.zeros((n, n))  # Initialize a square matrix with zeros
values_to_set = jnp.array(
    [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]
)  # Values to set in the matrix
row_indices = 2  # Row index to start updating from
col_indices = jnp.array([1, 2, 3])  # Column indices to update

updated_matrix = update_matrix_slices(matrix, values_to_set, row_indices, col_indices)
print(updated_matrix)


import jax
import jax.numpy as jnp


"""
Basically jax.lax.scan is a for loop that takes as an input the function to be
iterated, the initial value and the iterable. Every loop in python mainly
consist into two possibilities:
1) You prepare an empty variable and you perform inplace modifications
2) You want to perform different computations for each iteration

The function should have two ouputs:

The first one is called the "carry over" because it is passed to the next
iteration. The second one is the actual output of the function at step k.

-------------------------------------------------------------------------------

Imagin that you want to do an incremental update of a variable x. In that case,
you can start from an initial value x0 and add a value at each iteration k. In
that case, this is the "carry over" variable that is going to be updated.

For example:
x = np.array([1, 2, 3])
for k in range(2, 5):
    x += k
"""


def fcn(x, xs):
    """Body function to perform in the loop.

    We update the carry over and we don't care about the second one
    """
    return x + xs, None


out = jax.lax.scan(fcn, jnp.array([1, 2, 3]), jnp.arange(2, 5))
print(out)


"""
-------------------------------------------------------------------------------
In the second example, I'm not interested in the carry over but I want to
perform a different computation at each iteration.


Example :
out = np.zeros((10,))
for k in range(10):
    out[k] = x.sum() + k
"""


def fcn(x, xs):
    """Body function to perform in the loop.

    First output: leave x unchanged
    Second output: the value computed at step k
    """
    x_sum = x.sum()
    return x, x_sum + xs


x = jnp.array([1, 2, 3])
vec = jnp.arange(10)
out = jax.lax.scan(fcn, x, vec)
print(out)


"""
-------------------------------------------------------------------------------
And finally you can combine the two :

t = np.array([0, 0, 0])
for k in range(10):
    t += x.sum() + k
"""


def fcn(inputs, xs):
    """Body function to perform in the loop.

    First output: x unchanged but t is updated
    Second output: the value of the sum of x at step k
    """
    x, t = inputs
    t += x.sum() + xs
    return (x, t), x.sum() + xs


t = jnp.array([0, 0, 0])
x = jnp.array([1, 2, 3])
vec = jnp.arange(10)
out = jax.lax.scan(fcn, (x, t), vec)
print(out)


out[1]


x = jnp.zeros((2, 100))


jax.lax.dynamic_update_slice(x, jnp.array([2, 3, 4]), jnp.array([1, 1, 1]))


x = x.at[0, 2:10].set(1)


def fcn(inputs, xs):
    A, h = inputs

    A = A.at[xs, xs - 1 : xs + 2].set([h[xs - 1], 2 * (h[xs - 1] + h[xs]), h[xs]])

    return (A, h), None


def fcn(inputs, xs):
    A, h = inputs

    # A = A.at[xs, xs - 1 : xs + 2].set([h[xs - 1], 2 * (h[xs - 1] + h[xs]), h[xs]])

    A = jax.lax.dynamic_update_slice(
        A, ((xs), (xs - 1, xs, xs + 1)), [h[xs - 1], 2 * (h[xs - 1] + h[xs]), h[xs]]
    )
    return (A, h), None


x = jnp.zeros((10, 10))
h = jnp.ones(10)


import jax
import jax.numpy as jnp
from jax import lax


def fcn(inputs, xs):
    A, h = inputs

    # Construct the update values as a flat 1D array
    update_values = jnp.array(
        [h[xs - 1], 2 * (h[xs - 1] + h[xs]), h[xs]], dtype=jnp.float32
    )

    # Specify the slice indices
    row_indices = xs
    col_indices = (xs - 1, xs, xs + 1)

    # Use lax.dynamic_update_slice to update A
    A = jax.lax.dynamic_update_slice(A, update_values, (row_indices, col_indices))

    return (A, h), None


# Example usage
x = jnp.zeros((10, 10), dtype=jnp.float32)
h = jnp.ones(10, jnp.float32)

result, _ = fcn((x, h), jnp.array(5, dtype=np.int8))
print(result[0])


import jax
import jax.numpy as np
from jax import lax


def simple_while_loop(cond_fun, body_fun, init_val):
    def loop_body(carry):
        val, cond = carry
        next_val = body_fun(val)
        return next_val, cond_fun(next_val)

    final_val, _ = lax.while_loop(
        lambda carry: carry[1], loop_body, (init_val, cond_fun(init_val))
    )
    return final_val


# Example: Compute the sum of squares until the sum exceeds 100
def condition(x):
    return np.sum(x**2) < 100


def body(x):
    return x + 1


initial_value = np.zeros(1)
result = simple_while_loop(condition, body, initial_value)

print("Result:", result)


def EMD(X, t, max_IMF=jnp.inf):

    x = X.copy()
    IMFs = []
    nIMFs = 0

    def condition(x):
        return x > 0.3

    idx_max = None
    idx_min = None

    def body_fun(values):
        h, t, SD = values

        nonlocal idx_max, idx_min
        idx_max = _boolrelextrema_scan_greater(h)[0]
        idx_min = _boolrelextrema_scan_lesser(h)[0]

        if idx_max.shape[0] + idx_min.shape[0] < 2:
            return -1, -1, -1

        U = cubic_spline_eval(
            t, t[idx_max], *cubic_spline_interpolation(t[idx_max], h[idx_max])
        )
        L = cubic_spline_eval(
            t, t[idx_min], *cubic_spline_interpolation(t[idx_min], h[idx_min])
        )
        m = (U + L) / 2

        prevh = h.copy()
        h = h - m

        SD = jnp.sum(((prevh - h) ** 2) / (prevh**2 + 1e-6))

        return h, t, SD

    def _while(cond_fun, body_fun, init_val):
        h, t, SD = init_val

        def loop_body(carry):
            val, cond = carry
            if not cond:
                return val, False  # Break the loop if the condition is not met
            h, t, SD = body_fun(val)
            return (h, t, SD), cond_fun(SD)

        final_val, _ = jax.lax.while_loop(
            lambda carry: carry[1], loop_body, ((h, t, SD), cond_fun(SD))
        )
        return final_val

    while True:

        h = x.copy()
        SD = 1

        h, t, SD = _while(condition, body_fun, (h, t, SD))

        IMFs += [h]
        nIMFs += 1
        x = x - h

        if idx_max.shape[0] + idx_min.shape[0] < 2:
            break

    return IMFs


t = jnp.linspace(0, 0.2, 100)
x = (
    jnp.sin(2 * jnp.pi * 3 * t)
    + jnp.sin(2 * jnp.pi * 10 * t)
    + jnp.sin(2 * jnp.pi * 60 * t)
    + 0.5 * jnp.sin(2 * jnp.pi * 120 * t)
)


IMFs = EMD(x, t, max_IMF=jnp.inf)


IMFs


def fcn(inputs, xs):
    A, h = inputs

    # Construct the update values as a flat 1D array
    update_values = jnp.c_[(h[xs - 1], 2 * (h[xs - 1] + h[xs]), h[xs])].reshape(1, -1)

    # Use lax.dynamic_update_slice to update A
    A = lax.dynamic_update_slice(A, update_values, (xs, xs - 1))

    return (A, h), None


# Example usage
x = jnp.zeros((10, 10))
h = jnp.ones((10,))

result, _ = fcn((x, h), 5)
print(result[0])


import jax
import jax.numpy as jnp


@jax.jit
def optimizer(x, tol=1, max_steps=5):
    def cond(arg):
        step, x, history = arg
        return (step < max_steps) & (x > tol)

    def body(arg):
        step, x, history = arg
        x = x / 2  # simulate taking an optimizer step
        history = history.at[step].set(x)  # simulate saving current step
        return (step + 1, x, history)

    return jax.lax.while_loop(cond, body, (0, x, jnp.full(max_steps, jnp.nan)))


optimizer(10.0)  # works



