


import sys

sys.path.insert(1, "/home/vinicius/storage1/projects/vanderbilt")


import os

import emd
import igraph as ig
import matplotlib.pyplot as plt
import networkx as nx
import numpy as np
import PyEMD
import scipy
import skimage as ski
import umap
import xarray as xr
from frites.utils import parallel_func
from mne.time_frequency import tfr_array_morlet, tfr_array_multitaper
from scipy.optimize import curve_fit
from skimage.segmentation import watershed
from tqdm import tqdm

from config import metadata
from VUDA.burstdetection import detect_bursts
from VUDA.emd import emd_vec
from VUDA.io.loadbinary import LoadBinary





def find_start_end(array, find_zeros=False):
    """
    Given a binary array find the indexes where the sequences of ones start
    and begin if find_zeros is False. Otherwise it will find the indexes where
    the sequences of zeros start and begin. For instance, for the array
    [0,1,1,1,0,0], would return 1 and 3 respectively for find_zeros=False,
    and 1 and 2 for find_zeros=True.

    Parameters
    ----------
    array: array_like
        Binary array.
    find_zeros: bool | False
        Wheter to find a sequence of zeros or ones

    Returns
    -------
    The matrix containing the start anb ending index
    for each sequence of consecutive ones or zeros with shapes [n_seqs,2]
    where n_seqs is the number of sequences found.
    """
    if find_zeros:
        _bounds = np.array([1])
    else:
        _bounds = np.array([0])

    bounded = np.hstack((_bounds, array, _bounds))
    difs = np.diff(bounded)
    # get 1 at run starts and -1 at run ends if find_zeros is False
    if not find_zeros:
        (run_starts,) = np.where(difs > 0)
        (run_ends,) = np.where(difs < 0)
    # get -1 at run starts and 1 at run ends if find_zeros is True
    else:
        (run_starts,) = np.where(difs < 0)
        (run_ends,) = np.where(difs > 0)
    return np.vstack((run_starts, run_ends)).T


from functools import partial

import jax
import jax.numpy as jnp

jax.config.update("jax_platform_name", "cpu")


def get_bc(cycles, freq, k_sd=5):
    return cycles / (k_sd * freq)


def cxmorelet(freq, cycles, sampling_freq):
    t = jnp.linspace(-1, 1, sampling_freq * 2)

    bc = get_bc(cycles, freq)
    norm = 1 / (bc * jnp.sqrt(2 * jnp.pi))
    gauss = jnp.exp(-(t**2) / (2 * bc**2))
    sine = jnp.exp(1j * 2 * jnp.pi * freq * t)

    wavelet = norm * gauss * sine
    return wavelet / jnp.sum(jnp.abs(wavelet))


@partial(jax.jit, static_argnums=3)
@partial(jax.vmap, in_axes=(None, 0, None, None))
def wavelet_transform(signal, freq, cycles, sampling_freq):
    wavelet = cxmorelet(freq, cycles, sampling_freq)
    return jax.scipy.signal.convolve(signal, wavelet, mode="same")


@partial(jax.jit, static_argnums=3)
@partial(jax.vmap, in_axes=(None, None, 0, None))
def superlet_transform_helper(signal, freqs, order, sampling_freq):
    return wavelet_transform(signal, freqs, order, sampling_freq) * jnp.sqrt(2)


def order_to_cycles(base_cycle, max_order, mode):
    if mode == "add":
        return jnp.arange(0, max_order) + base_cycle
    elif mode == "mul":
        return jnp.arange(1, max_order + 1) * base_cycle
    else:
        raise ValueError('mode should be one of "mul" or "add"')


def get_order(f, f_min: int, f_max: int, o_min: int, o_max: int):
    return o_min + jnp.round((o_max - o_min) * (f - f_min) / (f_max - f_min))


@partial(jax.vmap, in_axes=(0, None))
def get_mask(order, max_order):
    return jnp.arange(1, max_order + 1) > order


@jax.jit
def norm_geomean(X, root_pows, eps):
    X = jnp.log(X + eps).sum(axis=0)

    return jnp.exp(X / jnp.array(root_pows).reshape(-1, 1))


# @jax.jit
def adaptive_superlet_transform(
    signal,
    freqs,
    sampling_freq: int,
    base_cycle: int,
    min_order: int,
    max_order: int,
    eps=1e-12,
    mode="mul",
):
    """Computes the adaptive superlet transform of the provided signal
    Args:
        signal (jnp.ndarray): 1D array containing the signal data
        freqs (jnp.ndarray): 1D sorted array containing the frequencies to compute the wavelets at
        sampling_freq (int): Sampling frequency of the signal
        base_cycle (int): The number of cycles corresponding to order=1
        min_order (int): The minimum upper limit of orders to be used for a frequency in the adaptive superlet.
        max_order (int): The maximum upper limit of orders to be used for a frequency in the adaptive superlet.

        eps (float, optional): Epsilon value to be used for numerical stability in the geometric mean. Defaults to 1e-12.
        mode (str, optional): "add" or "mul", corresponding to the use of additive or multiplicative adaptive superlets. Defaults to "mul".
    Returns:
        jnp.ndarray: 2D array (Frequency x Time) representing the computed scalogram
    """
    cycles = order_to_cycles(base_cycle, max_order, mode)
    orders = get_order(freqs, min(freqs), max(freqs), min_order, max_order)
    mask = get_mask(orders, max_order)

    out = superlet_transform_helper(signal, freqs, cycles, sampling_freq)
    out = out.at[mask.T].set(1)

    return norm_geomean(out, orders, eps)


def superlets(
    data,
    freqs,
    sampling_freq,
    base_cycle=3,
    min_order=1,
    max_order=30,
    eps=1e-12,
    mode="mul",
    block_size=None,
):
    if not isinstance(data, jax.numpy.ndarray):
        data = jnp.array(data)
    if not isinstance(freqs, jax.numpy.ndarray):
        freqs = jnp.array(freqs)

    n_trials, n_channels, n_times = data.shape

    if isinstance(block_size, int) and (block_size > 1):
        blocks = jnp.array_split(np.arange(n_trials), block_size)
    else:
        blocks = [jnp.arange(n_trials)]

    _fcn = partial(
        adaptive_superlet_transform,
        freqs=freqs,
        sampling_freq=sampling_freq,
        base_cycle=base_cycle,
        min_order=min_order,
        max_order=max_order,
        eps=eps,
        mode=mode,
    )

    tf = jax.vmap(jax.vmap(_fcn, in_axes=(0,)), in_axes=(0,))

    out = []
    for block in blocks:
        out += [
            jax.device_put(
                tf(data[blocks, ...]),
                jax.devices("cpu")[0],
            )
        ]

    return np.stack(out)


def to_bin_freq(freqs, peaks):

    n_blocks, n_peaks = peaks.shape
    n_freqs = freqs.shape[0]

    def _for_peak(carry, peak):

        vec = jnp.zeros(n_freqs, dtype=int)
        indexes = jnp.stack(
            [jnp.argmin(jnp.abs(freqs - peak[i])) for i in range(n_peaks)]
        )
        vec = vec.at[indexes].set(1)
        return carry, vec

    _, vec = jax.lax.scan(_for_peak, None, peaks)

    return np.asarray(vec)


import numba as nb


@nb.jit(nopython=True)
def arrays_equal(a, b):
    """
    Check if two arrays are equal.

    Parameters:
    - a (numpy.ndarray): First array.
    - b (numpy.ndarray): Second array.

    Returns:
    - bool: True if the arrays are equal, False otherwise.

    This function checks whether two arrays are equal by comparing their shapes
    and element-wise values.
    """
    if a.shape != b.shape:
        return False
    for ai, bi in zip(a.flat, b.flat):
        if ai != bi:
            return False
    return True


def return_labeled_image(img: np.ndarray = None, threshold: float = None):
    """
    Label regions in a binary image using a given threshold.

    Parameters:
    - img (numpy.ndarray): The binary image to label.
    - threshold (float): The threshold for labeling.

    Returns:
    - numpy.ndarray: A labeled image with connected regions.
    - numpy.ndarray: Array of unique labels.
    - int: The number of unique labels.

    This function labels connected regions in a binary image based on a given threshold.
    It uses the `ski.measure.label` function from the scikit-image library to perform
    the labeling. The resulting labeled image contains connected regions with unique
    labels, and the number of labels is also returned.
    """
    labeled_image = ski.label(img > threshold, background=0)
    labels = np.unique(labeled_image)[1:]
    nlabels = len(labels)
    return labeled_image, labels, nlabels


def detect_bursts(
    spectra: xr.DataArray,
    init_threshold: float = None,
    min_threshold: float = 0,
    gamma: float = 1,
    zscore_dims: tuple = None,
    verbose: bool = False,
):
    """
    Detect bursts in spectra using a dynamic thresholding approach.

    Parameters:
    - spectra (xarray.DataArray): The input spectra to analyze.
    - init_threshold (float): The initial threshold for labeling. If none uses the floor
                              of the maximum value in the zsored data.
    - min_threshold (float): The minimum threshold to stop the labeling process.
    - gamma (float): The step size for updating the threshold.
    - zscore_dims (tuple): Dimensions along which to compute z-scores.

    Returns:
    - numpy.ndarray: An image with labeled bursts.

    This function detects bursts in a given spectra by iteratively updating a labeling
    based on threshold values. It starts with an initial threshold, and in each iteration,
    it updates the labeling using a lower threshold. The process continues until the
    threshold reaches the minimum threshold value. The resulting labeled image contains
    burst regions.

    Note: The input spectra are first z-scored before applying labeling.
    """

    history = []

    size = spectra.shape
    z = (spectra - spectra.mean(zscore_dims)) / spectra.std(zscore_dims)
    return_labeled_image_partial = partial(return_labeled_image, img=z)

    if init_threshold is None:
        init_threshold = int(z.max(zscore_dims).min())  # int(np.max(z))

    # Create first labeld image
    labeled_image, labels, nlabels = return_labeled_image(z, init_threshold)

    history.append(labeled_image)
        
    thresholds = np.arange(init_threshold  - gamma, min_threshold, -gamma, dtype=float)
    thresholds = np.maximum(thresholds, 0)
    print(len(thresholds), thresholds)

    __iter = tqdm(thresholds) if verbose else thresholds

    # thr = init_threshold - gamma

    for thr in __iter:
        if verbose:
            __iter.set_description(f"threshold = {thr:.2f}")
        new_labeled_image, new_labels, new_nlabels = return_labeled_image_partial(
            threshold=thr
        )

        indexes = np.zeros(new_labeled_image.shape, dtype=np.bool_)

        for label in new_labels:
            mask = new_labeled_image == label
            unique_labels = np.unique(mask * labeled_image)
            if len(unique_labels) > 2:
                indexes = np.logical_or(indexes, mask)

        not_indexes = np.logical_not(indexes)
        new_labeled_image = new_labeled_image * not_indexes + labeled_image * indexes

        old_labeled_image = labeled_image.copy()

        labeled_image, labels, nlabels = return_labeled_image(new_labeled_image, 0)

        history.append(labeled_image)

        # Break if there is no evolution of patches
        #if arrays_equal(labeled_image > 0, old_labeled_image > 0):
        #    break

        del old_labeled_image

    return labeled_image, history





date = "10-13-2022"
monkey = "FN"
max_imfs = None
method = "eemd"
condition = "task"


composites_path = os.path.expanduser(
    f"~/funcog/HoffmanData/{monkey}/{date}/composite_signals_{condition}_method_eemd_max_imfs_None_std_False.nc"
)

ps_composites_path = os.path.expanduser(
    f"~/funcog/HoffmanData/{monkey}/{date}/ps_composite_signals_{condition}_method_eemd_max_imfs_None_std_False.nc"
)


composites = xr.open_dataset(composites_path)
ps_composites = xr.open_dataset(ps_composites_path)





kernel = np.hanning(50)


channels = list(composites.keys())


peaks = []

for channel in tqdm(channels):
    data = ps_composites[channel].dropna("IMFs")
    freqs = data.freqs.data

    data_sm = xr.DataArray(
        scipy.signal.fftconvolve(data, kernel[None, None, :], mode="same", axes=2),
        dims=data.dims,
        coords=data.coords,
    )

    freqs = data.freqs.data

    n_blocks, n_IMFs, n_freqs = data.shape

    peaks += [freqs[data_sm.argmax("freqs").data]]


plt.figure(figsize=(20, 20), dpi=600)
for pos in range(len(channels)):
    plt.subplot(10, 4, pos + 1)
    for i in range(peaks[pos].shape[1]):
        plt.scatter(peaks[pos][:, i], np.arange(200, dtype=int), s=5)
    plt.ylim(-3, 203)

    plt.xlabel("Frequency [Hz]")
    plt.ylabel("Blocks")
    plt.title(f"Channel {pos + 1}")
plt.tight_layout()


plt.figure(figsize=(15, 4))
d = []
for pos in range(len(channels)):
    x = peaks[pos].flatten()
    d += [x]
    plt.scatter(x, [pos + 1] * len(x), s=1, c="k")
plt.ylabel("Channel")
plt.xlabel("Frequency [Hz]")


hist, bins = np.histogram(np.hstack(peaks).flatten(), 100)


plt.figure(figsize=(15, 4))
plt.hist(np.hstack(peaks).flatten(), 100)
plt.step(bins[1:], (hist > 100) * 1000, c="r", lw=5);





channel = "channel1"


fvec = np.linspace(4, 150, 100)


1 / 150


X = composites[channel].dropna("IMFs")


W = tfr_array_multitaper(
    X.transpose("blocks", "IMFs", "times"),
    1000,
    fvec,
    n_cycles=6,
    time_bandwidth=4,
    decim=10,
    output="power",
    n_jobs=20,
).squeeze()

dims = ("batches", "IMFs", "freqs", "times")
coords = dict(freqs=fvec)

W = xr.DataArray(W, dims=dims, coords=coords)


freqs[ps_composites[channel].dropna("IMFs").argmax("freqs")].mean(0)


plt.figure(figsize=(20, 3.5), dpi=300)

for i in range(W.shape[1]):
    plt.subplot(1, 5, i + 1)
    W[100][i].plot(cmap="turbo")
    plt.title(f"composite {i + 1}")
plt.tight_layout()





from skimage import measure as ski


def get_init_threshold(W):
    z  = (W - W.mean("times")) / W.std("times")
    init_thr =  int(W.max().data.item())
    min_thr = z.quantile(.7)
    return z.quantile(.99).data.item(), z.quantile(.95).data.item()


get_init_threshold(W[:, 1])


z = (W - W.mean(("times", "freqs"))) / W.std(("times", "freqs"))


z.isel(batches=0, IMFs=3).plot(cmap="turbo", vmin=0, vmax=4)
plt.xlim(1500, 2000)


_, hist = detect_bursts(W[0, 1], 4, 1.5, .1, zscore_dims=("times", "freqs"), verbose=True)


plt.figure(figsize=(20, 20))
for i in range(24):
    plt.subplot(6, 4, i + 1)
    plt.imshow(
        hist[i] > 0,
        aspect="auto",
        origin="lower",
        cmap="binary",
    )
    plt.xlim(1500, 2000)


1/6 * 1000


for i in range(W.shape[1]):
    plt.figure(figsize=(12, 4))
    plt.subplot(1, 2, 1)
    W.isel(batches=0, IMFs=i).plot(cmap="turbo")
    plt.xlim(1500, 2000)
    plt.subplot(1, 2, 2)
    plt.imshow(
        detect_bursts(W[0, i], 3, 0, 0.5, zscore_dims=("times", "freqs"))[0] > 0,
        aspect="auto",
        origin="lower",
        cmap="binary",
    )
    plt.xlim(1500, 2000)





def weighted_avg_and_std(values, weights):
    """
    Return the weighted average and standard deviation.

    values, weights -- NumPy ndarrays with the same shape.
    """
    average = np.average(values, weights=weights)
    # Fast and numerically precise:
    variance = np.average((values - average) ** 2, weights=weights)
    return (average, np.sqrt(variance))


def extract_features(W, labeled_bursts):

    unique_labels = np.unique(labeled_bursts)[1:]
    nlabels = len(unique_labels)

    # Avg. and STD of each burst
    mean_amplitude = np.empty(nlabels)
    std_amplitude = np.empty(nlabels)

    # Avg., STD of the frequency of each burst and their weighted version
    mean_freq = np.empty(nlabels)
    std_freq = np.empty(nlabels)
    w_mean_freq = np.empty(nlabels)
    w_std_freq = np.empty(nlabels)
    peak_freq = np.empty(nlabels)

    # Avg., STD of the time of each burst and their weighted version
    mean_time = np.empty(nlabels)
    std_time = np.empty(nlabels)
    w_mean_time = np.empty(nlabels)
    w_std_time = np.empty(nlabels)
    t_start = np.empty(nlabels)
    t_stop = np.empty(nlabels)
    duration = np.empty(nlabels)

    labels_flattened = labeled_bursts.reshape(-1)
    W_stacked = W.stack(flat=("freqs", "times"))

    times = W_stacked.times.data
    freqs = W_stacked.freqs.data

    for pos, label in enumerate(unique_labels):
        mean_amplitude[pos] = W_stacked[labels_flattened == label].mean()
        std_amplitude[pos] = W_stacked[labels_flattened == label].std()

        mean_freq[pos] = freqs[labels_flattened == label].mean()
        std_freq[pos] = freqs[labels_flattened == label].std()
        w_mean_freq[pos], w_std_freq[pos] = weighted_avg_and_std(
            freqs[labels_flattened == label], W_stacked[labels_flattened == label]
        )
        peak_freq[pos] = freqs[labels_flattened == label].max()

        mean_time[pos] = times[labels_flattened == label].mean()
        std_time[pos] = times[labels_flattened == label].std()
        w_mean_time[pos], w_std_time[pos] = weighted_avg_and_std(
            times[labels_flattened == label], W_stacked[labels_flattened == label]
        )

        t_start[pos] = times[labels_flattened == label].min()
        t_stop[pos] = times[labels_flattened == label].max()

        duration[pos] = t_stop[pos] - t_start[pos]

    return (
        mean_amplitude,
        std_amplitude,
        mean_freq,
        std_freq,
        w_mean_freq,
        w_std_freq,
        peak_freq,
        mean_time,
        std_time,
        w_mean_time,
        w_std_time,
        t_start,
        t_stop,
        duration,
    )


def _for_batch(W):
    init = int(((W.max("times") - W.mean("times")) / W.std("times")).max().data.item())
    return detect_bursts(W, init, 0, 0.5, zscore_dims=("times", "freqs"))


int(((W.max("times") - W.mean("times")) / W.std("times")).max().data.item())


# define the function to compute in parallel
parallel, p_fun = parallel_func(_for_batch, verbose=False, n_jobs=20, total=200)

labeled_bursts = []
for ii in range(W.shape[1]):
    labeled_bursts += [parallel(p_fun(W) for W in W[:, ii])]
labeled_bursts = np.stack(labeled_bursts)


labeled_bursts = xr.DataArray(
    labeled_bursts, dims=("IMFs", "batches", "freqs", "times"), coords={"freqs": fvec}
)


labeled_bursts.to_netcdf("labeled_bursts.nc")
W.to_netcdf("spec.nc")


feature_names = [
    "mean_amplitude",
    "std_amplitude",
    "mean_freq",
    "std_freq",
    "w_mean_freq",
    "w_std_freq",
    "peak_freq",
    "mean_time",
    "std_time",
    "w_mean_time",
    "w_std_time",
    "t_start",
    "t_stop",
    "duration",
]

features = {}

for name in feature_names:

    features[name] = []

for i in tqdm(range(200)):
    out = extract_features(W[:, 0][i], labeled_bursts[0][i])
    for pos, name in enumerate(feature_names):
        features[name] += [out[pos]]


plt.figure(figsize=(12, 8))
pos = 1
for name in feature_names:
    if name not in ["t_start", "t_stop"]:
        plt.subplot(3, 4, pos)
        plt.hist(np.hstack(features[name]), 30)
        plt.title(name)
        pos = pos + 1
plt.tight_layout()


features_gamma = {}

for name in feature_names:

    features_gamma[name] = []

for i in tqdm(range(100)):
    out = extract_features(W_gamma[i], labeled_gamma_bursts[i])
    for pos, name in enumerate(feature_names):
        features_gamma[name] += [out[pos]]


plt.figure(figsize=(12, 8))
pos = 1
for name in feature_names:
    if name not in ["t_start", "t_stop"]:
        plt.subplot(3, 4, pos)
        plt.hist(np.hstack(features_gamma[name]), 30)
        plt.title(name)
        pos = pos + 1
plt.tight_layout()


import matplotlib as mpl

plt.figure(figsize=(9, 3.5))

plt.subplot(121)

plt.hist2d(
    np.hstack(features["mean_freq"]),
    np.log(np.hstack(features["mean_amplitude"])),
    bins=(20, 20),
    norm=mpl.colors.LogNorm(),
    cmap="turbo",
)
plt.ylabel("log(Amplitude)")
plt.xlabel("frequency [Hz]")
plt.title(r"$\theta$-bursts")
plt.colorbar()

plt.subplot(122)

plt.hist2d(
    np.hstack(features_gamma["mean_freq"]),
    np.log(np.hstack(features_gamma["mean_amplitude"])),
    bins=(20, 20),
    norm=mpl.colors.LogNorm(),
    cmap="turbo",
)
plt.ylabel("log(Amplitude)")
plt.xlabel("frequency [Hz]")
plt.title(r"$\gamma$-bursts")
plt.colorbar()

plt.tight_layout()


import numba as nb


@nb.njit
def overlaps(theta_timings: list, gamma_timings: list):
    n_theta = len(theta_timings)
    n_gamma = len(gamma_timings)

    n_overlaps = np.empty(n_gamma, dtype=np.int8)

    for i in range(n_gamma):
        temp = np.logical_and(
            theta_timings[:, 0] - gamma_timings[i, 0] < 0,
            theta_timings[:, 1] - gamma_timings[i, 0] > 0,
        )

        temp = np.logical_and(
            temp,
            np.logical_and(
                theta_timings[:, 0] - gamma_timings[i, 1] < 0,
                theta_timings[:, 1] - gamma_timings[i, 1] > 0,
            ),
        )

        n_overlaps[i] = temp.sum()

    return n_overlaps


n_overlaps = []

for i in range(100):

    T_theta = np.stack((features["t_start"][i], features["t_stop"][i]), axis=1)
    T_gamma = np.stack(
        (features_gamma["t_start"][i], features_gamma["t_stop"][i]), axis=1
    )

    n_overlaps += [overlaps(T_theta, T_gamma)]


n_overlaps = np.hstack(n_overlaps)
amplitudes = np.hstack(features_gamma["mean_amplitude"])


n_overlaps


plt.figure(figsize=(9, 3.5))

ax = plt.subplot(121)
n, x = np.histogram(n_overlaps, bins=[0, 1, 2, 3, 4])
plt.bar(x[:-1], n / n.sum())
plt.xlabel("#theta bursts per gamma burst")
[ax.spines[key].set_visible(False) for key in ["top", "right"]]
ax = plt.subplot(122)
import pandas as pd
import seaborn as sns

df = pd.DataFrame(
    np.stack((n_overlaps, amplitudes), axis=1), columns=["overlap", "amplitude"]
)
sns.boxplot(data=df, x="overlap", y="amplitude", showfliers=False, color="lightblue")
[ax.spines[key].set_visible(False) for key in ["top", "right"]]

plt.xticks(rotation=90)

plt.tight_layout()


SIZES = []
FREQS = []

for pos in tqdm(range(100)):

    times = W_gamma[pos].stack(flat=("freqs", "times")).times.data
    freqs = W_gamma[pos].stack(flat=("freqs", "times")).freqs.data

    labeled_bursts = labeled_gamma_bursts[pos].reshape(-1)

    unique_labels = np.unique(labeled_bursts)[1:]
    n_labels = len(unique_labels)

    S = np.zeros((n_labels, n_labels))
    F_min = np.zeros(n_labels)
    F_max = np.zeros(n_labels)
    F_mean = np.zeros(n_labels)

    for l_i in unique_labels - 1:
        F_min[l_i] = freqs[labeled_bursts == l_i + 1].min()
        F_max[l_i] = freqs[labeled_bursts == l_i + 1].max()
        F_mean[l_i] = freqs[labeled_bursts == l_i + 1].mean()

    for l_i in range(n_labels - 1):
        times_i = times[labeled_bursts == l_i + 1]
        s_i = len(times_i)
        for l_j in range(l_i, n_labels):
            if F_max[l_i] < F_min[l_j]:
                times_j = times[labeled_bursts == l_j + 1]
                s_j = len(times_j)
                S[l_i, l_j] = len(np.intersect1d(times_i, times_j)) / np.min((s_i, s_j))
    np.fill_diagonal(S, 0)
    SIZES += [S]
    FREQS += [F_mean]


x, y = [], []
for i in range(len(SIZES)):
    pi, pj = np.where(SIZES[i] > 0.95)
    x += [FREQS[i][pi]]
    y += [FREQS[i][pj]]

x = np.hstack(x)
y = np.hstack(y)
plt.hist2d(x, y, cmap="hot_r")
plt.xlabel("Frequency [Hz]")
plt.ylabel("Frequency [Hz]")
plt.title(r"Density of harmonic $\gamma$ bursts")
plt.colorbar()


SIZES = []
FREQS = []

for pos in tqdm(range(100)):

    times = W_theta[pos].stack(flat=("freqs", "times")).times.data
    freqs = W_theta[pos].stack(flat=("freqs", "times")).freqs.data

    labeled_bursts = labeled_theta_bursts[pos].reshape(-1)

    unique_labels = np.unique(labeled_bursts)[1:]
    n_labels = len(unique_labels)

    S = np.zeros((n_labels, n_labels))
    F_min = np.zeros(n_labels)
    F_max = np.zeros(n_labels)
    F_mean = np.zeros(n_labels)

    for l_i in unique_labels - 1:
        F_min[l_i] = freqs[labeled_bursts == l_i + 1].min()
        F_max[l_i] = freqs[labeled_bursts == l_i + 1].max()
        F_mean[l_i] = freqs[labeled_bursts == l_i + 1].mean()

    for l_i in range(n_labels - 1):
        times_i = times[labeled_bursts == l_i + 1]
        s_i = len(times_i)
        for l_j in range(l_i, n_labels):
            if F_max[l_i] < F_min[l_j]:
                times_j = times[labeled_bursts == l_j + 1]
                s_j = len(times_j)
                S[l_i, l_j] = len(np.intersect1d(times_i, times_j)) / np.min((s_i, s_j))
    np.fill_diagonal(S, 0)
    SIZES += [S]
    FREQS += [F_mean]


x, y = [], []
for i in range(len(SIZES)):
    pi, pj = np.where(SIZES[i] > 0.95)
    x += [FREQS[i][pi]]
    y += [FREQS[i][pj]]

x = np.hstack(x)
y = np.hstack(y)
plt.hist2d(x, y, cmap="hot_r", density=True)
plt.xlabel("Frequency [Hz]")
plt.ylabel("Frequency [Hz]")
plt.title(r"Density of harmonic $\theta$ bursts")
plt.colorbar()
