


import sys

sys.path.insert(1, "/home/vinicius/storage1/projects/vanderbilt")


import os

import emd
import matplotlib.pyplot as plt
import numpy as np
import PyEMD
import skimage as ski
import umap
import xarray as xr
from frites.utils import parallel_func
from mne.time_frequency import psd_array_multitaper
from scipy.optimize import curve_fit
from skimage.segmentation import watershed
from tqdm import tqdm

from VUDA.emd import emd_vec
from VUDA.io.loadbinary import LoadBinary





date = "10-20-2022"
monkey = "FN"


filepath = os.path.expanduser(f"~/funcog/HoffmanData/{monkey}/{date}/aHPC_B_cnct.nc")


data = xr.load_dataarray(filepath)


# Get zero timestamp
t_init = data.times.data[0]
# Get final timestamp
t_end = data.times.data[0]
# End of treehouse
t_th_end = float(data.attrs["TH_end"].split(", ")[1])
# Beggining of sleep
t_sleep_init = float(data.attrs["Sleep_start"].split(", ")[1])


data = data.sel(times=slice(t_init, t_th_end))


times = data.times.values


plt.figure(figsize=(20, 4))
ax = plt.subplot(111)
data.sel(channels=33).plot()
[ax.spines[key].set_visible(False) for key in ["top", "right"]];





def standardize_imf_per_block(IMFs):
    """
    Standardizes the number of intrinsic mode functions (IMFs) per block in an xarray Dataset.
    It sums slower IMFs in case a given block has more IMFs, thant the block that has the least
    number of IMFs.

    Parameters:
    - IMFs (xarray.Dataset): Input Dataset containing IMFs with dimensions ('blocks', 'IMFs', ...).

    Returns:
    - xarray.Dataset: Output Dataset with standardized IMFs per block.

    The function standardizes the number of IMFs per block by either summing the first
    (10 - n_imfs_min + 1) IMFs or keeping the original IMFs if the number is already less
    than or equal to n_imfs_min.

    Note:
    - The function assumes that the input Dataset has dimensions ('blocks', 'IMFs', ...).
    - The result is a new Dataset with standardized IMFs per block.
    """

    assert isinstance(IMFs, xr.DataArray)
    np.testing.assert_array_equal(IMFs.dims, ("blocks", "IMFs", "times"))

    n_imfs_min = IMFs.n_imfs_per_block.min()
    attrs = IMFs.attrs

    reduced = []

    for i in range(IMFs.sizes["blocks"]):

        temp = IMFs[i].dropna("IMFs").drop_vars("IMFs")
        n_imfs = temp.shape[0]

        if n_imfs > n_imfs_min:

            reduced += [
                xr.concat(
                    (
                        temp[0 : n_imfs - n_imfs_min + 1].sum("IMFs", keepdims=True),
                        temp[n_imfs - n_imfs_min + 1 :],
                    ),
                    "IMFs",
                )
            ]

        else:
            reduced += [temp]

    IMFs = xr.concat(reduced, "blocks")
    IMFs.attrs = attrs

    return IMFs


IMFs_single = emd_vec(
        data.sel(channels=33).values,
        times,
        method="eemd",
        max_imfs=None,
        block_size=200,
        nensembles=5,
        use_min_block_size=True,
        remove_fastest_imf=True,
        n_jobs=20,
        imf_opts={"stop_method": "fixed", "max_iters": 5},
    )


IMFs_single = standardize_imf_per_block(IMFs_single)


imf = IMFs_single[0].data

z_imf = (imf - imf.mean(1)[:, None]) / imf.std(1)[:, None]


fig, axd = plt.subplot_mosaic(
    [["A", "A", "C", "C"], ["B", "B", "C", "C"], ["B", "B", "C", "C"]],
    layout="constrained",
    figsize=(10, 5),
    dpi=600,
)

# Plot the signal snippet
plt.sca(axd["A"])
plt.plot(data.sel(channels=33).data)
plt.xlim(0, 5000)
plt.xlabel("Time [a.u]")
plt.ylabel(r"LFP [$\mu$V]")
[axd["A"].spines[key].set_visible(False) for key in ["top", "right"]]

# Plot the signal IMFs
plt.sca(axd["B"])
colors = []
for i in range(imf.shape[0]):
    p_ = plt.plot(z_imf[i] + 14.5 * (z_imf.shape[0] - i))
    colors += [p_[0].get_color()]
    plt.text(
        -490,
        14.5 * (z_imf.shape[0] - i),
        f"IMF {i + 1}",
        color=colors[-1],
        rotation=20,
    )
    plt.axis("off")


psd, f = psd_array_multitaper(
    imf,
    fmin=0,
    fmax=300,
    sfreq=1000,
    bandwidth=4,
    verbose=False,
    n_jobs=10,
)

plt.sca(axd["C"])
for i in range(len(psd)):
    plt.semilogx(f, psd[i] / psd[i].sum())
plt.xlabel("frequency [Hz]")
plt.ylabel("Norm. PSD")
[axd["C"].spines[key].set_visible(False) for key in ["top", "right"]];





IMFs = IMFs_single.stack(samples=("blocks", "IMFs")).T.dropna("samples")


SXX, f = psd_array_multitaper(
    IMFs,
    fmin=0,
    fmax=300,
    sfreq=1000,
    verbose=True,
    bandwidth=4,
    n_jobs=20,
)

SXX_norm = SXX / SXX.mean(1)[:, None]


reducer = umap.UMAP(n_jobs=20, min_dist=.5, n_neighbors=5, )
embedding = reducer.fit_transform(SXX_norm)


from sklearn.cluster import DBSCAN, KMeans, OPTICS

clustering = KMeans(
    n_clusters=6, init="k-means++", n_init="auto"
).fit(SXX_norm)

clustering = DBSCAN(
    eps=200, min_samples=20
).fit(SXX_norm)


clustering.labels_


plt.scatter(embedding[:, 0], embedding[:, 1], s=.5, c=clustering.labels_, cmap="tab10")


labels = clustering.labels_


from sklearn.metrics import pairwise_distances_argmin_min

if -1 in np.unique(labels):

    # Identify noise points
    noise_points = SXX_norm[labels == -1]
    
    # Find the closest cluster for each noise point
    closest_cluster_indices = pairwise_distances_argmin_min(noise_points, SXX_norm[labels != -1])[0]
    closest_cluster_labels = labels[closest_cluster_indices]
    
    # Assign noise points to the closest cluster
    labels[labels == -1] = closest_cluster_labels

    clustering.labels_ = labels


unique_labels = np.unique(clustering.labels_)


n_cluster = len(unique_labels)


from functools import partial

def average_for_cluster(data=None, cluster_labels=None, label=None):
    return data[cluster_labels == label].mean(0)

partial_average_for_cluster = partial(
    average_for_cluster, data=SXX_norm, cluster_labels=clustering.labels_
)

out = np.stack([partial_average_for_cluster(label=label) for label in unique_labels])

order = np.argsort(out.argmax(axis=1))


unique_labels[order]


plt.figure(figsize=(10, 5))
for pos, i in enumerate(unique_labels[order]):
    plt.subplot(3, 3, pos + 1)
    plt.semilogx(f, SXX_norm[clustering.labels_ == i].T, lw=.1, color="b")
    plt.semilogx(f, SXX_norm[clustering.labels_ == i].mean(0), lw=2, color="k")
    plt.xlabel("Frequency [Hz]")
    plt.ylabel("Norm. POWER")
plt.tight_layout()





n_blocks = IMFs_single.shape[0]


clustering.labels_[:10]


cluster_labels = clustering.labels_.reshape(-1 , IMFs_single.shape[1])


composite = []

for i in range(n_blocks):
    labels = cluster_labels[i]
    composite += [
        IMFs_single[i]
        .dropna("IMFs")
        .assign_coords({"IMFs": labels})
        .groupby("IMFs")
        .sum("IMFs")
    ]

composite = xr.concat(composite, "blocks")


SXX_composite, f = psd_array_multitaper(
    composite,
    fmin=0,
    fmax=300,
    sfreq=1000,
    verbose=True,
    bandwidth=4,
    n_jobs=20,
)


plt.figure(figsize=(10, 5))
for pos, i in enumerate(unique_labels[order]):
    plt.subplot(3, 3, pos + 1)
    plt.semilogx(f, SXX_composite[:, i, :].T, c="b", lw=.1 );
    plt.semilogx(f, np.nanmean(SXX_composite[:, i, :], 0), c="r", lw=3 );
plt.tight_layout()





date = "10-20-2022"
monkey = "FN"
max_imfs = None
method = "eemd"


IMFpath = os.path.expanduser(
    f"~/funcog/HoffmanData/{monkey}/{date}/IMFs_task_method_{method}_max_imfs_{max_imfs}.nc"
)


# Path in which to save figures
figures_path = f"figures/{monkey}/{date}"

if not os.path.isdir(figures_path):
    os.makedirs(figures_path)


IMFs_dataset = xr.load_dataset(IMFpath)


channels = list( IMFs_dataset.keys() )


for channel in channels:
    #################################################################
    # Get IMFs for channel
    #################################################################
    IMFs_single = IMFs_dataset[channel]

    IMFs = IMFs_single.stack(samples=("blocks", "IMFs")).T.dropna("samples")
    #################################################################
    # Compute power-spectrum for IMFs
    #################################################################
    SXX, f = psd_array_multitaper(
        IMFs,
        fmin=0,
        fmax=300,
        sfreq=1000,
        verbose=True,
        bandwidth=4,
        n_jobs=20,
    )

    SXX_norm = SXX / SXX.mean(1)[:, None]

    #################################################################
    # Embed power-spectra
    #################################################################
    reducer = umap.UMAP(
        n_jobs=20,
        min_dist=0.5,
        n_neighbors=5,
    )
    embedding = reducer.fit_transform(SXX_norm)

    # Cluster power-spectra
    clustering = DBSCAN(eps=200, min_samples=20).fit(SXX_norm)

    # Set noise points to the closest cluster
    if -1 in np.unique(labels):

        # Identify noise points
        noise_points = SXX_norm[labels == -1]

        # Find the closest cluster for each noise point
        closest_cluster_indices = pairwise_distances_argmin_min(
            noise_points, SXX_norm[labels != -1]
        )[0]
        closest_cluster_labels = labels[closest_cluster_indices]

        # Assign noise points to the closest cluster
        labels[labels == -1] = closest_cluster_labels

        clustering.labels_ = labels

    #################################################################
    # Plot embedding colored by cluster labels
    #################################################################
    plt.figure(figsize=(8, 8))
    ax = plt.subplot(111)
    plt.scatter(
        embedding[:, 0], embedding[:, 1], s=0.5, c=clustering.labels_, cmap="tab10"
    )
    plt.title(f"embedding IMFs - monkey {monkey} - date {date} - {channel}")
    plt.axis("off")
    plt.savefig(os.path.join(figures_path, f"embedding_imfs_{channel}.png"))
    plt.close()

    #################################################################
    # Plot spectra for each cluster
    #################################################################
    plt.figure(figsize=(10, 5))
    ax = plt.subplot(111)
    for pos, i in enumerate(unique_labels[order]):
        plt.subplot(3, 3, pos + 1)
        plt.semilogx(f, SXX_norm[clustering.labels_ == i].T, lw=0.1, color="b")
        plt.semilogx(f, SXX_norm[clustering.labels_ == i].mean(0), lw=2, color="k")
        plt.xlabel("Frequency [Hz]")
        plt.ylabel("Norm. POWER")
        [ax.spines[key].set_visible(False) for key in ["top", "right"]]
    plt.tight_layout()
    plt.savefig(os.path.join(figures_path, f"clustered_imf_spectra_{channel}.png"))
    plt.close()

    #################################################################
    # Generate composite signals
    #################################################################
    n_blocks = IMFs_single.shape[0]
    cluster_labels = clustering.labels_.reshape(-1, IMFs_single.shape[1])

    composite = []

    for i in range(n_blocks):
        labels = cluster_labels[i]
        composite += [
            IMFs_single[i]
            .dropna("IMFs")
            .assign_coords({"IMFs": labels})
            .groupby("IMFs")
            .sum("IMFs")
        ]

    composite = xr.concat(composite, "blocks")

    #################################################################
    # Compute power-spectrum for composite signals
    #################################################################
    SXX_composite, f = psd_array_multitaper(
        composite,
        fmin=0,
        fmax=300,
        sfreq=1000,
        verbose=True,
        bandwidth=4,
        n_jobs=20,
    )

    plt.figure(figsize=(10, 5))
    ax = plt.subplot(111)
    for pos, i in enumerate(unique_labels[order]):
        plt.subplot(3, 3, pos + 1)
        plt.semilogx(f, SXX_composite[:, i, :].T, c="b", lw=0.1)
        plt.semilogx(f, np.nanmean(SXX_composite[:, i, :], 0), c="r", lw=3)
        plt.xlabel("Frequency [Hz]")
        plt.ylabel("Norm. POWER")
        [ax.spines[key].set_visible(False) for key in ["top", "right"]]
    plt.tight_layout()
    plt.savefig(
        os.path.join(figures_path, f"clustered_composites_spectra_{channel}.png")
    )
    plt.close()



