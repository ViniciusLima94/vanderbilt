


import os

import matplotlib.pyplot as plt
import numpy as np
import PyEMD
from mne.time_frequency import (
    psd_array_multitaper,
    tfr_array_morlet,
    tfr_array_multitaper,
)
from tqdm import tqdm

from VUDA.io.loadbinary import LoadBinary





import logging

from frites.utils import parallel_func


def _emd(
    data: np.ndarray,
    trials: int,
    max_imf: int = 10,
    block_size=None,
    n_jobs: int = 1,
    verbose: bool = False,
    seed: int = 0,
    method="emd",
):

    assert method in ["emd", "eemd"]

    if method == "emd":
        logging.warning("For method EMD, trials is set to 1.")
        trials = 1

    n_samples = data.shape[0]

    _emd = PyEMD.EEMD(trials=trials)
    _emd.noise_seed(seed)

    if method == "emd":
        f_emd = _emd.emd
    else:
        f_emd = _emd.eemd

    if isinstance(block_size, int) and (block_size > 1):
        blocks = np.array_split(np.arange(n_samples), block_size)
    else:
        blocks = [np.arange(n_samples)]

    nblocks = len(blocks)

    IMDs = []

    def _for_block(block):

        return _emd.eemd(data[block], progress=False, max_imf=max_imf)

    # define the function to compute in parallel
    parallel, p_fun = parallel_func(
        _for_block, verbose=verbose, n_jobs=n_jobs, total=nblocks
    )

    out = parallel(p_fun(block) for block in blocks)

    return out


def get_composite_signal(
    IMFs: list,
    sfreq: int,
    cutoff: int,
    fmin=0,
    fmax=300,
    bandwidth=4,
    n_jobs=1,
    verbose: bool = False,
):

    n_trials = len(IMFs)

    __iter = range(ntrials)

    filtered = []
    psds = []
    freqs = []

    def _for_trial(i):

        psd, f = psd_array_multitaper(
            IMFs[i],
            fmin=fmin,
            fmax=fmax,
            sfreq=sfreq,
            verbose=False,
            bandwidth=bandwidth,
            n_jobs=n_jobs,
        )

        psd = np.log(psd)

        freqs += [f]
        idx = np.where(f[psd.argmax(axis=1)] > cutoff)[0]
        filtered += [IMFs[i][idx].mean(0)]
        psds += [psd[idx].mean(0)]

    for i in __iter:

        psd, f = psd_array_multitaper(
            IMFs[i],
            fmin=fmin,
            fmax=fmax,
            sfreq=sfreq,
            verbose=False,
            bandwidth=bandwidth,
            n_jobs=n_jobs,
        )

        psd = np.log(psd)

        freqs += [f]
        idx = np.where(f[psd.argmax(axis=1)] > 40)[0]
        filtered += [IMFs[i][idx].mean(0)]
        psds += [psd[idx].mean(0)]





filepath = "/home/vinicius/funcog/vanderbilt/neural_data/aHPC_B_cnct.dat"


# Load binaries
data = LoadBinary(
    filepath,
    frequency=30000,
    nSamplesPerChannel=None,
    channels=[33],
    downsample=30,
    bitVolts=0.195,
    nChannels=64,
    precision=np.int16,
    verbose=False,
)


# Decompose in IMFs
IMFs = _emd(
    data.squeeze().data,
    trials=50,
    max_imf=None,
    method="eemd",
    block_size=1000,
    n_jobs=30,
    verbose=True,
)


plt.figure(figsize=(20, 4))
data.plot()


def gaussian_fit(y, x):

    popt, pcov = curve_fit(gauss, x, y, p0=[1, x[y.argmax()], 1])

    return popt[1] - popt[2], popt[1] + popt[2]


filtered = []
psds = []
freqs = []

low_cutoff = 30
high_cutoff = 200

for i in tqdm(range(10)):

    psd, f = psd_array_multitaper(
        IMFs[i], fmin=0, fmax=300, sfreq=1000, verbose=False, bandwidth=4, n_jobs=30
    )

    popt = np.apply_along_axis(gaussian_fit, 1, psd, f)
    bw_0, bw_1 = popt[1] - popt[2], popt[1] + popt[2]

    freqs += [f]
    idx = np.where(bw_0 >= low_cutoff)[0]
    filtered += [IMFs[i][idx].sum(0)]
    psds += [psd[idx].mean(0)]


psds


from scipy.optimize import curve_fit

plt.figure(figsize=(20, 5))

for i in range(10):
    plt.plot(f, psds[i], "b")


i = 5
plt.figure(figsize=(10, 10))
plt.subplot(3, 1, 1)
plt.plot(filtered[i])
plt.xlim(0, 16000)
plt.subplot(3, 1, 3)
psd, f = psd_array_multitaper(
    filtered[i], fmin=0, fmax=300, sfreq=1000, verbose=False, bandwidth=12, n_jobs=30
)
plt.plot(f, psd, "b")
plt.subplot(3, 1, 2)
freqs = np.linspace(10, 200, 100)
W = tfr_array_morlet(
    filtered[i][None, None, :],
    1000,
    freqs,
    n_cycles=freqs,
    n_jobs=1,
)
W = (W * np.conj(W)).real.squeeze()
W = (W - W.mean()) / W.std()
plt.imshow(W, aspect="auto", cmap="turbo", origin="lower", vmax=5)
z_filtered = (filtered[i] - filtered[i].mean()) / filtered[i].std()
plt.plot(filtered[i] + 60, "w", lw=1)
plt.xlim(5000, 10000)


plt.plot(f, np.array(psds).mean(0))
plt.vlines(low_cutoff, 0, 1300, "r")


filtered_ct = np.concatenate(filtered)


freqs = np.linspace(10, 200, 100)
W = tfr_array_morlet(
    filtered[0][None, None, :],
    1000,
    freqs,
    n_cycles=freqs,
    n_jobs=1,
)
W = (W * np.conj(W)).real.squeeze()


plt.imshow(W, aspect="auto", cmap="turbo", origin="lower", vmax=4000)
plt.yticks(np.arange(len(freqs))[::5], np.round(freqs[::5]).astype(int))
plt.ylabel("frequency [Hz]")
plt.xlabel("time")
plt.colorbar()





emd = PyEMD.EEMD(trials=10, parallel=False)


out = emd.eemd(data.values.squeeze()[:10000], progress=True)


out_z = (out - out.mean(1)[:, None]) / out.std(1)[:, None]


import matplotlib.ticker as mticker

plt.figure(figsize=(10, 4), dpi=600)
plt.subplot(1, 2, 1)
for i in range(out.shape[0]):
    p_ = plt.plot(out_z[i] + 15 * (out.shape[0] - i))
    plt.text(-220, 15 * (out.shape[0] - i), f"IMF {i + 1}", color=p_[0].get_color())
    plt.axis("off")
ax = plt.subplot(1, 2, 2)
for i in range(out.shape[0]):
    psds, freqs = psd_array_multitaper(
        out[i], fmin=0, fmax=300, sfreq=1000, verbose=False, bandwidth=4, n_jobs=10
    )
    psds = (psds - psds.mean()) / psds.std()
    ax.plot(freqs, psds, label=f"IMF {i + 1}")

    ax.set_xlim(freqs.min(), freqs.max())
    ax.set_xscale("log")
    formatter = mticker.ScalarFormatter()
    ax.xaxis.set_major_formatter(formatter)
    ax.xaxis.set_major_locator(mticker.FixedLocator([1, 5, 10, 15, 40, 80, 120, 250]))
    [ax.spines[key].set_visible(False) for key in ["top", "right"]]
plt.ylabel("z(Power)")
plt.xlabel("Frequency [Hz]")
plt.legend(frameon=False)


composite = out[:3].mean(axis=0)


freqs = np.linspace(10, 200, 30)
W = tfr_array_morlet(composite[None, None, :], 1000, freqs, n_cycles=freqs / 2)
W = (W * np.conj(W)).real.squeeze()


plt.imshow(W, aspect="auto", cmap="turbo", origin="lower", vmax=2000)
plt.yticks(np.arange(len(freqs))[::5], np.round(freqs[::5]).astype(int))
plt.ylabel("frequency [Hz]")
plt.xlabel("time")
plt.colorbar()


z = (W - W.mean(1)[:, None]) / W.std(1)[:, None]


plt.imshow(
    ski.measure.label(z > 1.22, background=0) == 3, aspect="auto", origin="lower"
)
plt.colorbar()


import skimage as ski


nblobs = []
for i in np.linspace(0, 6, 100)[::-1]:
    nblobs += [np.unique(ski.measure.label(z > i, background=0)).shape[0]]


plt.plot(np.linspace(0, 6, 100)[::-1], nblobs)
plt.ylabel("#gamma bursts")
plt.xlabel("threshold")


labeld_image = ski.measure.label(z > 3, background=0)
labels = np.unique(labeld_image)[1:]  # Exclude backgroud
nlabels = len(labels)

new_labeld_image = ski.measure.label(z > 1, background=0)
new_labels = np.unique(new_labeld_image)[1:]  # Exclude backgroud
nex_nlabels = len(new_labels)

temp = labeld_image.copy().reshape(-1)
max_label = labels.max()
for nl in new_labels:
    intersection = []
    index_nl = np.where(new_labeld_image.flatten() == nl)[0]
    for l in labels:
        index_l = np.where(labeld_image.flatten() == l)[0]
        if len(np.intersect1d(index_l, index_nl)) > 1:
            intersection.append(l)

    if len(intersection) > 0:
        intersection = np.hstack(intersection)
        indexes = np.where(np.in1d(temp, intersection))
        new_l = intersection.max()
        temp[index_nl] = new_l
    else:
        max_label = max_label + 1
        temp[index_nl] = max_label


plt.imshow(labeld_image, origin="lower", aspect="auto", cmap="turbo")


plt.imshow(new_labeld_image, origin="lower", aspect="auto", cmap="turbo")


temp = temp.reshape(labeld_image.shape)


un = np.unique(temp)
nun = len(un)


un


plt.figure(figsize=(20, 20))
for i in range(1, 31):
    plt.subplot(6, 5, i)
    plt.imshow(temp == i, origin="lower", aspect="auto", cmap="gray")


from scipy.interpolate import UnivariateSpline
from scipy.signal import find_peaks


t = np.linspace(0, 1, 1000)
x = np.random.normal(0, 1, size=len(t))

peaks, _ = find_peaks(np.abs(x))


plt.figure(figsize=(15, 4))
plt.plot(t, x)
plt.plot(t[peaks], x[peaks], ".")


spl = UnivariateSpline(t[peaks], x[peaks])


plt.figure(figsize=(15, 4))
plt.plot(t, x - np.mean((x, spl(t)), 0))


def EMD(t, data, max_imf=1):

    IMFs = []

    for i in range(max_imf):
        # Find local maxima/minima
        maxima, _ = find_peaks(data)
        minima, _ = find_peaks(data)
        # Fit a spline to the peaks
        spl = UnivariateSpline(t[peaks], data[peaks])
        # First component
        h = data - np.mean((data, spl(t)), axis=0)
        IMFs += [h.copy()]
        # Update data
        data = h

    return np.stack(IMFs)


out = EMD(t, x, max_imf=20)


out_z = (out - out.mean(1)[:, None]) / out.std(1)[:, None]


for i in range(out.shape[0]):
    p_ = plt.plot(out_z[i] + 15 * (out.shape[0] - i))
    plt.text(-220, 15 * (out.shape[0] - i), f"IMF {i + 1}", color=p_[0].get_color())
    plt.axis("off")


plt.plot(t, x)
plt.plot(t, np.abs(x).max() - x)


plt.plot(t, x)



